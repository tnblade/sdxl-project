# fine_turning/lora.py
# Script kh·ªüi ch·∫°y qu√° tr√¨nh fine-tuning LoRA cho SDXL 
# S·ª≠ d·ª•ng script chu·∫©n t·ª´ th∆∞ vi·ªán Diffusers c·ªßa HuggingFace v·ªõi m·ªôt s·ªë c·∫•u h√¨nh t·ªëi ∆∞u cho T4 


import os
import subprocess
import argparse
import sys

# --- M·ªöI: Hack ƒë∆∞·ªùng d·∫´n ƒë·ªÉ import ƒë∆∞·ª£c Config t·ª´ th∆∞ m·ª•c cha ---
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from core.config import Config
# -------------------------------------------------------------

SCRIPT_URL = "https://raw.githubusercontent.com/huggingface/diffusers/main/examples/text_to_image/train_text_to_image_lora_sdxl.py"
SCRIPT_NAME = "train_lora_sdxl_script.py"

def download_script():
    """T·∫£i script training LoRA chu·∫©n t·ª´ HuggingFace"""
    if not os.path.exists(SCRIPT_NAME):
        print(f"‚è≥ [LoRA] ƒêang t·∫£i script chu·∫©n: {SCRIPT_NAME}...")
        try:
            subprocess.run(["wget", "-q", SCRIPT_URL, "-O", SCRIPT_NAME], check=True)
            print("‚úÖ ƒê√£ t·∫£i xong script LoRA.")
        except Exception as e:
            print(f"‚ùå L·ªói t·∫£i script: {e}")
            sys.exit(1)
    else:
        print(f"‚úÖ ƒê√£ t√¨m th·∫•y script LoRA: {SCRIPT_NAME}")

def run_lora_training(data_dir, output_dir, prompt, base_model_path):
    if output_dir is None:
        output_dir = "output_lora_result"

    # In ra ƒë·ªÉ ki·ªÉm tra xem n√≥ nh·∫≠n ƒë√∫ng model Kaggle ch∆∞a
    print(f"üõ†Ô∏è Base Model Path: {base_model_path}")

    cmd = [
        "accelerate", "launch", SCRIPT_NAME,
        f"--pretrained_model_name_or_path={base_model_path}",
        f"--train_data_dir={data_dir}",
        "--caption_column=text",
        "--resolution=1024",
        "--random_flip",
        "--train_batch_size=1",
        "--num_train_epochs=10",          
        "--checkpointing_steps=500",
        "--learning_rate=1e-4",
        "--lr_scheduler=constant",
        "--lr_warmup_steps=0",
        "--mixed_precision=fp16",
        "--seed=42",
        f"--output_dir={output_dir}",
        f"--validation_prompt={prompt}",
        "--gradient_checkpointing",       
        "--use_8bit_adam",
        "--report_to=tensorboard",
        "--logging_dir=logs"
    ]

    print(f"\nüöÄ [LoRA] B·∫ÆT ƒê·∫¶U TRAINING...")
    try:
        subprocess.run(cmd, check=True)
        print(f"\n‚úÖ [LoRA] Ho√†n t·∫•t! File t·∫°i: {output_dir}/pytorch_lora_weights.safetensors")
    except subprocess.CalledProcessError as e:
        print(f"\n‚ùå [LoRA] L·ªói training: {e}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--data_dir", type=str, required=True, help="Folder ·∫£nh train")
    parser.add_argument("--prompt", type=str, required=True, help="Prompt k√≠ch ho·∫°t")
    parser.add_argument("--output_dir", type=str, default=None, help="Folder l∆∞u k·∫øt qu·∫£")
    
    # Cho ph√©p ng∆∞·ªùi d√πng truy·ªÅn model path th·ªß c√¥ng, n·∫øu kh√¥ng th√¨ t·ª± l·∫•y t·ª´ Config
    parser.add_argument("--base_model", type=str, default=None, help="ƒê∆∞·ªùng d·∫´n Base Model (T√πy ch·ªçn)")
    
    args = parser.parse_args()
    
    os.chdir(os.path.dirname(os.path.abspath(__file__)))
    download_script()
    
    # LOGIC M·ªöI: T·ª± ƒë·ªông x√°c ƒë·ªãnh model path
    if args.base_model:
        final_model_path = args.base_model
    else:
        final_model_path = Config.get_model_path()
    
    run_lora_training(args.data_dir, args.output_dir, args.prompt, final_model_path)