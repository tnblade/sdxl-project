# tools/perf_stats.py
# CÃ´ng cá»¥ Ä‘o hiá»‡u suáº¥t táº¡o áº£nh giá»¯a model gá»‘c vÃ  model fine-tuned báº±ng LoRA
# So sÃ¡nh thá»i gian táº¡o áº£nh vÃ  má»©c tiÃªu thá»¥ VRAM

import sys
import os
import time
import torch
import matplotlib.pyplot as plt
import argparse
import numpy as np

# Hack import core
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from core import SDXLManager

def measure_performance(manager, prompt, name):
    print(f"\nâš¡ Äang Ä‘o hiá»‡u suáº¥t: {name}...")
    
    # 1. Reset bá»™ nhá»› Ä‘á»ƒ Ä‘o chÃ­nh xÃ¡c
    torch.cuda.empty_cache()
    torch.cuda.reset_peak_memory_stats()
    
    # 2. Báº¯t Ä‘áº§u báº¥m giá»
    start_time = time.time()
    
    # 3. Cháº¡y thá»­ 1 áº£nh
    manager.generate(
        prompt=prompt, negative_prompt="", 
        steps=30, width=1024, height=1024, 
        seed=42, num_images=1
    )
    
    # 4. Káº¿t thÃºc báº¥m giá»
    end_time = time.time()
    duration = end_time - start_time
    
    # 5. Láº¥y Ä‘á»‰nh bá»™ nhá»› (Peak VRAM)
    max_memory = torch.cuda.max_memory_allocated() / (1024 ** 3) # Äá»•i sang GB
    
    print(f"   â±ï¸ Thá»i gian: {duration:.2f}s")
    print(f"   ğŸ’¾ VRAM Max: {max_memory:.2f}GB")
    
    return duration, max_memory

def plot_charts(base_stats, lora_stats, output_file="performance_report.png"):
    labels = ['Base Model', 'Fine-tuned (LoRA)']
    times = [base_stats[0], lora_stats[0]]
    vrams = [base_stats[1], lora_stats[1]]
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
    
    # Biá»ƒu Ä‘á»“ 1: Thá»i gian (Tháº¥p hÆ¡n lÃ  tá»‘t hÆ¡n)
    ax1.bar(labels, times, color=['#3498db', '#e74c3c'])
    ax1.set_title('Tá»‘c Ä‘á»™ táº¡o áº£nh (GiÃ¢y) - Tháº¥p hÆ¡n lÃ  tá»‘t')
    ax1.set_ylabel('GiÃ¢y')
    for i, v in enumerate(times):
        ax1.text(i, v + 0.5, f"{v:.2f}s", ha='center', fontweight='bold')

    # Biá»ƒu Ä‘á»“ 2: VRAM (Tháº¥p hÆ¡n lÃ  tá»‘t hÆ¡n)
    ax2.bar(labels, vrams, color=['#2ecc71', '#9b59b6'])
    ax2.set_title('Má»©c tiÃªu thá»¥ VRAM (GB)')
    ax2.set_ylabel('GB')
    for i, v in enumerate(vrams):
        ax2.text(i, v + 0.1, f"{v:.2f}GB", ha='center', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig(output_file)
    print(f"\nğŸ“Š ÄÃ£ lÆ°u biá»ƒu Ä‘á»“ so sÃ¡nh táº¡i: {output_file}")

def run_stats(prompt, lora_path):
    manager = SDXLManager()
    
    # 1. Äo Base Model
    manager.loader.unload_lora()
    base_stats = measure_performance(manager, prompt, "Base Model")
    
    # 2. Äo LoRA Model
    manager.loader.load_lora(lora_path)
    lora_stats = measure_performance(manager, prompt, "LoRA Model")
    
    # 3. Váº½ biá»ƒu Ä‘á»“
    plot_charts(base_stats, lora_stats)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--prompt", type=str, default="a cat", help="Prompt Ä‘á»ƒ test")
    parser.add_argument("--lora_path", type=str, required=True, help="ÄÆ°á»ng dáº«n file LoRA")
    args = parser.parse_args()
    
    run_stats(args.prompt, args.lora_path)