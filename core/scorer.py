# core/scorer.py
# B·ªô ph·∫≠n ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng ·∫£nh t·∫°o ra d·ª±a tr√™n CLIP Score v√† Aesthetic Score

import torch
import clip
from PIL import Image
import torch.nn as nn
import os
import urllib.request

class AestheticPredictor(nn.Module):
    """M·∫°ng Neural nh·ªè ƒë·ªÉ d·ª± ƒëo√°n ƒë·ªô th·∫©m m·ªπ (Aesthetic)"""
    def __init__(self, input_size):
        super().__init__()
        self.input_size = input_size
        self.layers = nn.Sequential(
            nn.Linear(self.input_size, 1024),
            nn.Dropout(0.2),
            nn.ReLU(),
            nn.Linear(1024, 128),
            nn.Dropout(0.2),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.Dropout(0.1),
            nn.ReLU(),
            nn.Linear(64, 16),
            nn.Linear(16, 1)
        )

    def forward(self, x):
        return self.layers(x)

class ImageScorer:
    def __init__(self, device="cuda" if torch.cuda.is_available() else "cpu"):
        self.device = device
        self.clip_model = None
        self.preprocess = None
        self.aesthetic_model = None
        
        # ƒê∆∞·ªùng d·∫´n l∆∞u model aesthetic
        self.aesthetic_path = "aesthetic_predictor.pth"
        self.aesthetic_url = "https://github.com/christophschuhmann/improved-aesthetic-predictor/raw/main/sac+logos+ava1-l14-linearMSE.pth"

    def load_models(self):
        """Ch·ªâ load khi c·∫ßn d√πng ƒë·ªÉ ti·∫øt ki·ªám VRAM"""
        if self.clip_model is None:
            print("üìä Loading CLIP for scoring...")
            # Load CLIP ViT-L/14 (Chu·∫©n ph·ªï bi·∫øn)
            self.clip_model, self.preprocess = clip.load("ViT-L/14", device=self.device)
            
            # Load Aesthetic Model
            if not os.path.exists(self.aesthetic_path):
                print("Downloading Aesthetic Model...")
                urllib.request.urlretrieve(self.aesthetic_url, self.aesthetic_path)
            
            self.aesthetic_model = AestheticPredictor(768)
            self.aesthetic_model.load_state_dict(torch.load(self.aesthetic_path))
            self.aesthetic_model.to(self.device)
            self.aesthetic_model.eval()
            print("‚úÖ Scoring models loaded.")

    def get_scores(self, image, prompt):
        """Tr·∫£ v·ªÅ Aesthetic Score (1-10) v√† CLIP Score (0-100)"""
        self.load_models()
        
        # X·ª≠ l√Ω ·∫£nh v√† text
        image_input = self.preprocess(image).unsqueeze(0).to(self.device)
        text_input = clip.tokenize([prompt], truncate=True).to(self.device)

        with torch.no_grad():
            # 1. T√≠nh CLIP Embeddings
            image_features = self.clip_model.encode_image(image_input)
            text_features = self.clip_model.encode_text(text_input)
            
            # Chu·∫©n h√≥a vector
            image_features /= image_features.norm(dim=-1, keepdim=True)
            text_features /= text_features.norm(dim=-1, keepdim=True)

            # 2. T√≠nh CLIP Score (ƒê·ªô t∆∞∆°ng ƒë·ªìng cosine * 100)
            clip_score = (image_features @ text_features.T).item() * 100
            
            # 3. T√≠nh Aesthetic Score
            # Aesthetic model input l√† CLIP image features (float32)
            aesthetic_score = self.aesthetic_model(image_features.float()).item()

        return round(clip_score, 2), round(aesthetic_score, 2)
        
    def unload(self):
        """Gi·∫£i ph√≥ng RAM khi kh√¥ng d√πng"""
        self.clip_model = None
        self.aesthetic_model = None
        torch.cuda.empty_cache()