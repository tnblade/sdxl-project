#   core/loaders.py
# ƒê√¢y l√† "th·ªß kho". Nhi·ªám v·ª• duy nh·∫•t l√† Load Model. Sau n√†y s·∫Ω th√™m h√†m load_lora, load_controlnet v√†o class n√†y c·ª±c k·ª≥ g·ªçn g√†ng.

import torch
import os
from diffusers import AutoPipelineForText2Image, AutoPipelineForImage2Image
from .config import Config

class ModelLoader:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.pipeline = None
        self.current_type = None # "txt2img" ho·∫∑c "img2img"

    def load_base_pipeline(self, task_type="txt2img"):
        """Load model linh ho·∫°t: H·ªó tr·ª£ c·∫£ Folder l·∫´n Single File (.safetensors)"""
        
        # 1. Load m·ªõi n·∫øu ch∆∞a c√≥
        if self.pipeline is None:
            model_id = Config.get_model_path()
            print(f"üì• Loading Base Model from: {model_id}...")
            
            # --- LOGIC M·ªöI: T·ª∞ ƒê·ªòNG NH·∫¨N DI·ªÜN LO·∫†I MODEL ---
            if str(model_id).endswith(".safetensors"):
                print("‚ö° Ph√°t hi·ªán Single File (.safetensors) -> D√πng from_single_file")
                # D√†nh cho Kaggle Input ho·∫∑c file t·∫£i v·ªÅ l·∫ª
                self.pipeline = AutoPipelineForText2Image.from_single_file(
                    model_id, 
                    torch_dtype=torch.float16, 
                    use_safetensors=True
                )
            else:
                print("‚òÅÔ∏è Ph√°t hi·ªán Folder/Repo -> D√πng from_pretrained")
                # D√†nh cho HuggingFace Repo ho·∫∑c th∆∞ m·ª•c ƒë√£ gi·∫£i n√©n
                self.pipeline = AutoPipelineForText2Image.from_pretrained(
                    model_id, 
                    torch_dtype=torch.float16, 
                    variant="fp16", 
                    use_safetensors=True
                )
            # -----------------------------------------------

            # T·ªëi ∆∞u b·ªô nh·ªõ cho T4/P100
            self.pipeline.enable_model_cpu_offload()
            print("‚úÖ Model loaded successfully.")

        # 2. Chuy·ªÉn ƒë·ªïi pipeline (Txt2Img <-> Img2Img) m√† kh√¥ng load l·∫°i RAM
        if task_type == "img2img" and self.current_type != "img2img":
            print("üîÑ Switching to Img2Img pipeline...")
            self.pipeline = AutoPipelineForImage2Image.from_pipe(self.pipeline)
            self.current_type = "img2img"
            
        elif task_type == "txt2img" and self.current_type != "txt2img":
            print("üîÑ Switching to Txt2Img pipeline...")
            self.pipeline = AutoPipelineForText2Image.from_pipe(self.pipeline)
            self.current_type = "txt2img"
            
        return self.pipeline

    def load_lora(self, lora_path, adapter_name="default"):
        if self.pipeline:
            print(f"Bm Loading LoRA adapter: {lora_path}")
            try:
                self.pipeline.load_lora_weights(lora_path, adapter_name=adapter_name)
                self.pipeline.fuse_lora() # G·ªôp weights ƒë·ªÉ ch·∫°y nhanh h∆°n
                print("‚úÖ LoRA Loaded & Fused.")
            except Exception as e:
                print(f"‚ùå L·ªói load LoRA: {e}")

    def unload_lora(self):
        if self.pipeline:
            print(f"Bm Unloading LoRA...")
            self.pipeline.unfuse_lora()
            self.pipeline.unload_lora_weights()
            print("‚úÖ LoRA Unloaded.")